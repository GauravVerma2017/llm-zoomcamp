{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2ea1e0-c430-46b4-b15e-8e4e1345690a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:52:57.625162Z",
     "iopub.status.busy": "2024-06-29T10:52:57.624639Z",
     "iopub.status.idle": "2024-06-29T10:52:58.253113Z",
     "shell.execute_reply": "2024-06-29T10:52:58.252480Z",
     "shell.execute_reply.started": "2024-06-29T10:52:57.625126Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         100G   39G   62G  39% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\n",
      "/dev/nvme0n1p1  100G   39G   62G  39% /run\n",
      "tmpfs            14G     0   14G   0% /dev/shm\n",
      "/dev/nvme2n1    2.0G  1.4M  1.9G   1% /home/jovyan\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\n",
      "tmpfs           7.7G  3.7M  7.7G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5952c0-f966-4fcd-b84f-7c8d75980409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:52:58.255024Z",
     "iopub.status.busy": "2024-06-29T10:52:58.254681Z",
     "iopub.status.idle": "2024-06-29T10:52:58.258567Z",
     "shell.execute_reply": "2024-06-29T10:52:58.257924Z",
     "shell.execute_reply.started": "2024-06-29T10:52:58.255002Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506fab2a-a50c-42bd-a106-c83a9d2828ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:52:58.259676Z",
     "iopub.status.busy": "2024-06-29T10:52:58.259423Z",
     "iopub.status.idle": "2024-06-29T10:52:59.483688Z",
     "shell.execute_reply": "2024-06-29T10:52:59.482936Z",
     "shell.execute_reply.started": "2024-06-29T10:52:58.259655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-29 10:52:59--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-06-29 10:52:59 (67.2 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac947de-effd-4b61-8792-a6d7a133f347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:52:59.485149Z",
     "iopub.status.busy": "2024-06-29T10:52:59.484834Z",
     "iopub.status.idle": "2024-06-29T10:53:00.696667Z",
     "shell.execute_reply": "2024-06-29T10:53:00.695818Z",
     "shell.execute_reply.started": "2024-06-29T10:52:59.485125Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7fc9e78b58b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/GauravVerma2017/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f087272-b44d-4738-9ea2-175ec63a058b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:53:00.697996Z",
     "iopub.status.busy": "2024-06-29T10:53:00.697615Z",
     "iopub.status.idle": "2024-06-29T10:53:00.701737Z",
     "shell.execute_reply": "2024-06-29T10:53:00.701133Z",
     "shell.execute_reply.started": "2024-06-29T10:53:00.697974Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8bff3e-b672-42be-866b-f2d9bb217106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:53:00.711411Z",
     "iopub.status.busy": "2024-06-29T10:53:00.710820Z",
     "iopub.status.idle": "2024-06-29T10:53:00.714906Z",
     "shell.execute_reply": "2024-06-29T10:53:00.714197Z",
     "shell.execute_reply.started": "2024-06-29T10:53:00.711388Z"
    }
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1f4d64-fa89-43d9-985e-f2120e239c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:53:00.716522Z",
     "iopub.status.busy": "2024-06-29T10:53:00.715939Z",
     "iopub.status.idle": "2024-06-29T10:53:03.022804Z",
     "shell.execute_reply": "2024-06-29T10:53:03.022197Z",
     "shell.execute_reply.started": "2024-06-29T10:53:00.716490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4770a6a3-bd4f-4f7d-a51a-2710071dcd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T11:04:20.857365Z",
     "iopub.status.busy": "2024-06-29T11:04:20.856952Z",
     "iopub.status.idle": "2024-06-29T11:04:23.475723Z",
     "shell.execute_reply": "2024-06-29T11:04:23.475074Z",
     "shell.execute_reply.started": "2024-06-29T11:04:20.857338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74550f5b21c44ec93214c2b846e25f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# download model from huggingface\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97b7af52-3fd0-472b-a6c9-a73c9c0bbbb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T11:10:57.871344Z",
     "iopub.status.busy": "2024-06-29T11:10:57.871065Z",
     "iopub.status.idle": "2024-06-29T11:10:57.877542Z",
     "shell.execute_reply": "2024-06-29T11:10:57.876768Z",
     "shell.execute_reply.started": "2024-06-29T11:10:57.871323Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt, generate_params=None):\n",
    "    if generate_params is None:\n",
    "        generate_params = {}\n",
    "        \n",
    "    #convert text into model input tokens\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(input_ids,\n",
    "                             max_length=generate_params.get(\"max_length\", 100),\n",
    "                             temperature=generate_params.get(\"temperature\", 1.0),\n",
    "                             top_k=generate_params.get(\"top_k\", 50),\n",
    "                             top_p=generate_params.get(\"top_p\", 0.95)\n",
    "                            )\n",
    "\n",
    "    #convert model output into text\n",
    "    response = tokenizer.decode(outputs[0], skip_special_token=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8c3a89b-a35a-4df5-a727-6e5bb40b87e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T11:09:41.049691Z",
     "iopub.status.busy": "2024-06-29T11:09:41.049312Z",
     "iopub.status.idle": "2024-06-29T11:10:57.869912Z",
     "shell.execute_reply": "2024-06-29T11:10:57.869037Z",
     "shell.execute_reply.started": "2024-06-29T11:09:41.049666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<pad> Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.</s>\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"can I join the course after it is started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab0e43-ed8b-4185-a312-1959efcc7ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
